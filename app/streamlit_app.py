# streamlit run app/streamlit_app.py
import streamlit as st
import os
import requests
import joblib
from dotenv import load_dotenv
from pathlib import Path
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch
from langchain_google_genai import ChatGoogleGenerativeAI
import time
import logging
import re

# Logging konfigÃ¼rasyonu
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Ã‡evresel deÄŸiÅŸkenleri yÃ¼kle
load_dotenv()
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")
HUGGINGFACEHUB_API_TOKEN = os.getenv("HUGGINGFACEHUB_API_TOKEN")

# Proje dizin yollarÄ±
BASE_DIR = Path(__file__).resolve().parent.parent
RESULTS_DIR = BASE_DIR / "results"

# Ã–ne Ã§Ä±kan sohbet Ã¶rnekleri
FEATURED_CHATS = [
    "Pamuk ve polyesterin Ã§evresel etkileri nelerdir?",
    "SÃ¼rdÃ¼rÃ¼lebilir tekstil ne demektir?",
    "Hangi kumaÅŸ tÃ¼rleri daha az karbon ayak izine sahiptir?",
    "Tekstil Ã¼retiminde su tÃ¼ketimi nasÄ±l azaltÄ±labilir?",
    "Geri dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmÃ¼ÅŸ polyester nedir?",
    "Organik pamuk neden daha iyi bir seÃ§enektir?"
]

# Niyet prompt ÅŸablonlarÄ±
INTENT_PROMPTS = {
    "Selamlama": "Merhaba! HoÅŸ geldiniz. BugÃ¼n tekstil ve moda hakkÄ±nda konuÅŸabiliriz. Size nasÄ±l yardÄ±mcÄ± olabilirim?",
    "Vedalasma": "TeÅŸekkÃ¼rler! EÄŸer tekstil ve moda Ã¼zerine daha fazla bilgi almak isterseniz, her zaman buradayÄ±m. GÃ¶rÃ¼ÅŸmek Ã¼zere!",
    "Malzeme_Turu": "FarklÄ± tekstil malzeme tÃ¼rlerini ve bunlarÄ±n Ã§evresel etkilerini aÃ§Ä±kla. Ã–rneÄŸin pamuk, polyester, yÃ¼n gibi malzemelerin avantaj ve dezavantajlarÄ±nÄ± detaylÄ± ÅŸekilde anlat.",
    "Malzeme_Karbon_Ayak_Ä°z": "Belirli malzemelerin karbon ayak izini karÅŸÄ±laÅŸtÄ±r ve aÃ§Ä±klamalar yap. Karbon ayak izi aÃ§Ä±sÄ±ndan en iyi ve en kÃ¶tÃ¼ performans gÃ¶steren malzemeleri sÄ±rala.",
    "Uretim_Sureci": "Tekstil Ã¼retim sÃ¼reÃ§lerinin Ã§evresel etkilerini ve iyileÅŸtirme yollarÄ±nÄ± anlat. SÃ¼rdÃ¼rÃ¼lebilir Ã¼retim teknikleri hakkÄ±nda bilgi ver.",
    "Surdurulebilirlik_Tanimi": "SÃ¼rdÃ¼rÃ¼lebilirliÄŸin tekstil baÄŸlamÄ±nda ne anlama geldiÄŸini aÃ§Ä±kla. Ã‡evresel, sosyal ve ekonomik boyutlarÄ±yla aÃ§Ä±kla.",
    "Oneri_Alternatif": "Daha sÃ¼rdÃ¼rÃ¼lebilir tekstil alternatiflerini Ã¶ner. KullanÄ±cÄ±nÄ±n ihtiyacÄ±na gÃ¶re Ã¶neriler sun.",
    "Bilinclendirme": "KullanÄ±cÄ±ya sÃ¼rdÃ¼rÃ¼lebilir tekstil konusunda bilinÃ§ kazandÄ±r. AlÄ±ÅŸveriÅŸ yaparken nelere dikkat etmesi gerektiÄŸini anlat.",
    "Etiketleme_Sorusu": "SÃ¼rdÃ¼rÃ¼lebilir etiketlerin anlamlarÄ±nÄ± ve kullanÄ±cÄ±ya nasÄ±l yardÄ±mcÄ± olacaÄŸÄ±nÄ± aÃ§Ä±kla. GOTS, Oeko-Tex gibi sertifikalarÄ± aÃ§Ä±kla.",
    "Cevre_Etkisi_Karsilastirma": "FarklÄ± tekstil uygulamalarÄ±nÄ±n Ã§evresel etkilerini karÅŸÄ±laÅŸtÄ±r. SayÄ±sal verilerle destekle.",
    "Yonetmelik_Politika": "Tekstil sektÃ¶rÃ¼ndeki sÃ¼rdÃ¼rÃ¼lebilirlik politikalarÄ±nÄ± ve yÃ¶netmelikleri anlat. KÃ¼resel ve yerel dÃ¼zenlemelerden bahset.",
    "Geri_Donusum": "Tekstilde geri dÃ¶nÃ¼ÅŸÃ¼mÃ¼n Ã¶nemi, sÃ¼reÃ§leri ve faydalarÄ±nÄ± aÃ§Ä±kla. Geri dÃ¶nÃ¼ÅŸÃ¼mÃ¼n Ã§evresel etkilerini anlat.",
    "Teknik_Tekstil": "Teknik tekstillerin sÃ¼rdÃ¼rÃ¼lebilirlik aÃ§Ä±sÄ±ndan katkÄ±larÄ±nÄ± aÃ§Ä±kla. AkÄ±llÄ± tekstillerin avantajlarÄ±ndan bahset.",
    "Karbon_Ayak_Ä°zi_Hesaplama": "Karbon ayak izi hesaplamasÄ±nÄ±n nasÄ±l yapÄ±ldÄ±ÄŸÄ±nÄ± sade bir ÅŸekilde aÃ§Ä±kla. Ã–rnek bir hesaplama gÃ¶ster.",
    "Yanlis_Bilgi_Duzeltme": "KullanÄ±cÄ±nÄ±n sÃ¼rdÃ¼rÃ¼lebilirlikle ilgili yanlÄ±ÅŸ bilgisini nazikÃ§e dÃ¼zelt. DoÄŸru bilgiyi kaynaklarla destekle.",
    "Genel": "SÃ¼rdÃ¼rÃ¼lebilir tekstil hakkÄ±nda detaylÄ± ve bilimsel bir aÃ§Ä±klama yap. Konuyla ilgili gÃ¼ncel veriler ve istatistikler ekle."
}


def clean_response(text):
    """Hugging Face yanÄ±tlarÄ±nÄ± Ã¶zel olarak temizle"""
    # Prompt kalÄ±ntÄ±larÄ±nÄ± temizle
    text = re.sub(r'\[SORU\].*?\[YANIT FORMATI\]', '', text, flags=re.DOTALL)

    # Modelin kendi kendine konuÅŸmasÄ±nÄ± temizle
    text = re.sub(r'(?i)(as an ai|as a language model|as an assistant).*?(response|answer)', '', text)

    # YaygÄ±n artefaktlarÄ± temizle
    text = re.sub(r'<\/?(div|p|span|br)[^>]*>', '', text)
    text = re.sub(r'\[INST\]|\[\/INST\]', '', text)

    # Fazla boÅŸluklarÄ± temizle
    text = re.sub(r'\n\s*\n', '\n\n', text)

    return text.strip()


# CSS ve animasyonlar
def add_custom_css():
    """Ã–zel CSS stilleri ekle"""
    st.markdown("""
    <style>
        /* Ana konteyner stili */
        .stApp {
            background: #f8fafc;
            font-family: 'Inter', sans-serif;
        }

        /* BaÅŸlÄ±k stili */
        [data-testid="stHeader"] {
            background: linear-gradient(90deg, #2563eb 0%, #1d4ed8 100%);
            color: white;
            padding: 1rem 1rem 4rem;
            box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1);
        }

        /* BaÅŸlÄ±k metni */
        .header-title {
            font-size: 1.8rem;
            font-weight: 700;
            margin-bottom: 0.25rem;
            text-align: center;
            animation: pulse 2s infinite;
        }

        /* BaÅŸlÄ±k alt metni */
        .header-subtitle {
            font-size: 1rem;
            opacity: 0.9;
            text-align: center;
        }

        /* Model seÃ§im butonlarÄ± */
        .stButton>button {
            transition: all 0.3s ease !important;
            border-radius: 0.5rem !important;
            font-weight: 600 !important;
            padding: 0.75rem 1.5rem !important;
        }

        /* Birincil buton (seÃ§ili model) */
        .stButton>button[kind="primary"] {
            background: linear-gradient(135deg, #3b82f6 0%, #2563eb 100%) !important;
            box-shadow: 0 1px 3px 0 rgba(0, 0, 0, 0.1), 0 1px 2px 0 rgba(0, 0, 0, 0.06) !important;
        }

        /* Ä°kincil buton (seÃ§ili olmayan) */
        .stButton>button[kind="secondary"] {
            background: white !important;
            color: #1e293b !important;
            border: 1px solid #e2e8f0 !important;
        }

        /* Sohbet konteyneri */
        .chat-container {
            height: calc(50vh - 380px);
            overflow-y: auto;
            padding: 1rem;
            scroll-behavior: smooth;
            background-color: #f8fafc;
            border-radius: 0.75rem;
            margin-bottom: 1rem;
            box-shadow: 0 1px 3px 0 rgba(0, 0, 0, 0.1);
        }

        /* KullanÄ±cÄ± mesajÄ± */
        .user-message {
            background: linear-gradient(135deg, #3b82f6 0%, #2563eb 100%);
            color: white;
            padding: 0.75rem 1.25rem;
            border-radius: 1rem 1rem 0 1rem;
            margin: 0.5rem 0;
            max-width: 80%;
            margin-left: auto;
            box-shadow: 0 1px 3px 0 rgba(0, 0, 0, 0.1);
            animation: fadeIn 0.3s ease-out;
        }

        /* Bot mesajÄ± - Temel stil */
        .bot-message {
            background: white;
            color: #1e293b;
            padding: 0.75rem 1.25rem;
            border-radius: 1rem 1rem 1rem 0;
            margin: 0.5rem 0;
            max-width: 80%;
            margin-right: auto;
            box-shadow: 0 1px 2px 0 rgba(0, 0, 0, 0.05);
            animation: fadeIn 0.3s ease-out;
            position: relative;
        }

        /* Hugging Face mesajÄ± */
        .bot-message.huggingface {
            border-left: 3px solid #10b981;
        }

        /* Gemini mesajÄ± */
        .bot-message.gemini {
            border-left: 3px solid #3b82f6;
        }

        /* Hugging Face balon iÅŸaretÃ§isi */
        .bot-message.huggingface::before {
            content: "ğŸ¤—";
            position: absolute;
            left: -30px;
            top: 0;
            font-size: 1.2rem;
        }

        /* Gemini balon iÅŸaretÃ§isi */
        .bot-message.gemini::before {
            content: "â™Š";
            position: absolute;
            left: -30px;
            top: 0;
            font-size: 1.2rem;
        }

        /* GiriÅŸ alanÄ± */
        .input-container {
            position: fixed;
            bottom: 0;
            left: 0;
            right: 0;
            background: white;
            padding: 1rem;
            box-shadow: 0 -4px 6px -1px rgba(0, 0, 0, 0.1);
            z-index: 100;
        }

        /* Metin alanÄ± */
        .stTextArea textarea {
            border-radius: 0.75rem !important;
            border: 1px solid #e2e8f0 !important;
            padding: 1rem !important;
            min-height: 100px !important;
        }

        /* Animasyonlar */
        @keyframes fadeIn {
            from { opacity: 0; transform: translateY(10px); }
            to { opacity: 1; transform: translateY(0); }
        }

        @keyframes slideIn {
            from { transform: translateY(20px); opacity: 0; }
            to { transform: translateY(0); opacity: 1; }
        }

        @keyframes pulse {
            0% { transform: scale(1); }
            50% { transform: scale(1.02); }
            100% { transform: scale(1); }
        }

        /* KaydÄ±rma Ã§ubuÄŸu */
        ::-webkit-scrollbar {
            width: 6px;
        }

        ::-webkit-scrollbar-track {
            background: #f1f5f9;
        }

        ::-webkit-scrollbar-thumb {
            background: #cbd5e1;
            border-radius: 3px;
        }

        /* Streamlit'in varsayÄ±lan padding'ini kaldÄ±r */
        .main .block-container {
            padding-top: 2rem;
            padding-bottom: 6rem;
        }

        /* Altbilgiyi kaldÄ±r */
        footer {visibility: hidden;}

        /* Ã–ne Ã§Ä±kan sohbet butonlarÄ± */
        .featured-chat {
            background: white !important;
            border: 1px solid #e2e8f0 !important;
            color: #1e293b !important;
            border-radius: 0.75rem !important;
            padding: 0.75rem 1rem !important;
            margin: 0.25rem 0 !important;
            text-align: left !important;
            transition: all 0.2s ease !important;
            box-shadow: 0 1px 2px 0 rgba(0, 0, 0, 0.05) !important;
        }

        .featured-chat:hover {
            background: #f1f5f9 !important;
            transform: translateY(-2px) !important;
            box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1) !important;
        }

        .model-selection-text {
            text-align: center;
            margin-bottom: 1rem;
            color: #64748b;
            font-size: 0.9rem;
        }

        /* Temizle butonu */
        .clear-button {
            background: #f8fafc !important;
            color: #dc2626 !important;
            border: 1px solid #dc2626 !important;
            margin-top: 0.5rem !important;
        }

        .clear-button:hover {
            background: #dc2626 !important;
            color: white !important;
        }

        /* Yeni buton dÃ¼zeni iÃ§in stiller */
        .input-buttons-container {
            display: flex;
            gap: 10px;
        }

        .clear-btn {
            flex: 1;
        }

        .submit-btn {
            flex: 1;
        }
    </style>
    """, unsafe_allow_html=True)


@st.cache_resource
def load_gemini_model():
    """Gemini niyet sÄ±nÄ±flandÄ±rma modelini yÃ¼kle"""
    try:
        model_path = RESULTS_DIR / "gemini_trained_model" / "gemini_pipeline.pkl"
        return joblib.load(model_path)
    except Exception as e:
        logger.error(f"Gemini modeli yÃ¼klenirken hata: {str(e)}")
        raise


@st.cache_resource
def load_hf_transformer_model():
    """Hugging Face niyet sÄ±nÄ±flandÄ±rma modelini yÃ¼kle"""
    try:
        model_dir = RESULTS_DIR / "hf_trained_model"
        tokenizer = AutoTokenizer.from_pretrained(model_dir)
        model = AutoModelForSequenceClassification.from_pretrained(model_dir)
        return tokenizer, model
    except Exception as e:
        logger.error(f"Hugging Face modeli yÃ¼klenirken hata: {str(e)}")
        raise


def hf_predict_intent(text, tokenizer, model):
    """Hugging Face modeli ile niyet tahmini yap"""
    try:
        model.eval()
        inputs = tokenizer(
            text,
            return_tensors="pt",
            truncation=True,
            padding=True,
            max_length=200
        )

        with torch.no_grad():
            outputs = model(**inputs)

        logits = outputs.logits
        predicted_class_id = int(torch.argmax(logits, dim=1).item())
        confidence = torch.softmax(logits, dim=1)[0][predicted_class_id].item()

        # EÅŸik deÄŸer kontrolÃ¼ (0.7)
        if confidence < 0.7:
            return "Genel"

        return model.config.id2label[predicted_class_id]
    except Exception as e:
        logger.error(f"Niyet tahmini yapÄ±lÄ±rken hata: {str(e)}")
        return "Genel"


def generate_hf_response(prompt, max_retries=3):
    """Hugging Face API ile yanÄ±t oluÅŸtur"""
    MODELS = [
        "HuggingFaceH4/zephyr-7b-beta"
    ]

    headers = {"Authorization": f"Bearer {HUGGINGFACEHUB_API_TOKEN}"}

    for model in MODELS:
        api_url = f"https://api-inference.huggingface.co/models/{model}"

        # YENÄ° ve DAHA GÃœVENLÄ° PROMPT FORMATI
        optimized_prompt = f"""
        [SORU]
        {prompt}

        [YANIT FORMATI]
        - Sadece sorunun yanÄ±tÄ±nÄ± ver
        - Kendi talimatlarÄ±nÄ± veya prompt detaylarÄ±nÄ± tekrarlama
        - DoÄŸal bir sohbet dili kullan
        - YanÄ±tÄ±na direkt konuya girerek baÅŸla
        - Maximum 3 paragraf uzunluÄŸunda
        """

        payload = {
            "inputs": optimized_prompt,
            "parameters": {
                "max_new_tokens": 400,
                "temperature": 0.5,
                "top_p": 0.9,
                "do_sample": True,
                "eos_token_id": 50256,
                "return_full_text": False  # BU Ã–NEMLÄ°: Promptu yanÄ±tta gÃ¶sterme
            }
        }

        for attempt in range(max_retries):
            try:
                response = requests.post(api_url, headers=headers, json=payload, timeout=30)
                response.raise_for_status()
                result = response.json()

                if isinstance(result, list) and len(result) > 0:
                    response_text = result[0].get("generated_text", "").strip()
                    return clean_response(response_text.split("[YANIT FORMATI]")[0])

            except requests.exceptions.RequestException as e:
                logger.warning(f"{attempt + 1}. deneme {model} modeli ile baÅŸarÄ±sÄ±z oldu: {str(e)}")
                if attempt < max_retries - 1:
                    time.sleep(2 ** attempt)
                continue

    return "ÃœzgÃ¼nÃ¼m, ÅŸu anda teknik bir sorun nedeniyle cevap veremiyorum. LÃ¼tfen daha sonra tekrar deneyin."


def generate_gemini_response(prompt):
    """Google Gemini ile yanÄ±t oluÅŸtur"""
    try:
        llm = ChatGoogleGenerativeAI(
            model="gemini-1.5-pro",
            temperature=0.4,
            max_tokens=500,
            google_api_key=GOOGLE_API_KEY
        )
        response = llm.invoke(prompt).content
        return clean_response(response)
    except Exception as e:
        logger.error(f"Gemini yanÄ±tÄ± oluÅŸturulurken hata: {str(e)}")
        return "ÃœzgÃ¼nÃ¼m, bir hata oluÅŸtu. LÃ¼tfen daha sonra tekrar deneyin."


def build_prompt(intent, user_input):
    """Niyete gÃ¶re optimize edilmiÅŸ prompt oluÅŸtur"""
    base_prompt = INTENT_PROMPTS.get(intent, INTENT_PROMPTS["Genel"])

    return f"""
    {base_prompt}

    KullanÄ±cÄ± Sorusu: {user_input}

    - CevaplarÄ±nÄ± **kÄ±sa, aÃ§Ä±k ve anlaÅŸÄ±lÄ±r** tut.
    - KullanÄ±cÄ±nÄ±n **sorduÄŸu dilde** yanÄ±t ver.
    - Nazik ve **doÄŸal bir sohbet akÄ±ÅŸÄ± koru**.
    - CÃ¼mlelerini **tamamla**, eksik veya yarÄ±m bÄ±rakma.
    - YanÄ±tlarÄ±n **verilen alana tam olarak sÄ±ÄŸmalÄ±**, kesilmemeli.
    """


def show_featured_chats():
    """Ã–ne Ã§Ä±kan sohbet Ã¶rneklerini gÃ¶ster"""
    st.markdown("**Ã–ne Ã‡Ä±kan Sohbet Ã–rnekleri**")
    cols = st.columns(2)
    for i, chat in enumerate(FEATURED_CHATS):
        with cols[i % 2]:
            if st.button(chat, key=f"featured_{chat}", use_container_width=True,
                         type="secondary", help="Bu soruyu sormak iÃ§in tÄ±klayÄ±n"):
                st.session_state.user_input = chat
                st.session_state.trigger_submit = True


def clear_chat_history():
    """Sohbet geÃ§miÅŸini temizle"""
    st.session_state.chat_history = []
    st.session_state.user_input = ""  # KullanÄ±cÄ± giriÅŸ alanÄ±nÄ± temizle
    st.session_state.trigger_submit = False
    st.rerun()  # SayfayÄ± yenile


def main():
    # Sayfa konfigÃ¼rasyonu
    st.set_page_config(
        page_title="SÃ¼rdÃ¼rÃ¼lebilir Tekstil Chatbot",
        page_icon="ğŸŒ¿",
        layout="wide",
        initial_sidebar_state="collapsed",
        menu_items={
            'Get Help': 'https://example.com',
            'Report a bug': "https://example.com",
            'About': "# SÃ¼rdÃ¼rÃ¼lebilir Tekstil Chatbot"
        }
    )

    # Ã–zel CSS ekle
    add_custom_css()

    # Oturum durumu yÃ¶netimi
    if 'chat_history' not in st.session_state:
        st.session_state.chat_history = []
        st.session_state.first_visit = True
    else:
        st.session_state.first_visit = False

    if 'trigger_submit' not in st.session_state:
        st.session_state.trigger_submit = False

    if 'selected_model' not in st.session_state:
        st.session_state.selected_model = "Gemini"

    # Ã–zel baÅŸlÄ±k
    st.markdown("""
    <div class="header-title">SÃ¼rdÃ¼rÃ¼lebilir Tekstil Chatbot</div>
    <div class="header-subtitle">SÃ¼rdÃ¼rÃ¼lebilir tekstil hakkÄ±nda bilgi almak iÃ§in sohbet edin</div>
    """, unsafe_allow_html=True)

    # Model seÃ§imi
    st.markdown('<div class="model-selection-text">LÃ¼tfen model seÃ§iniz</div>', unsafe_allow_html=True)
    col1, col2 = st.columns(2, gap="small")

    with col1:
        if st.button("Gemini", key="gemini_model",
                     type="primary" if st.session_state.selected_model == "Gemini" else "secondary"):
            st.session_state.selected_model = "Gemini"
            st.rerun()

    with col2:
        if st.button("Hugging Face", key="huggingface_model",
                     type="primary" if st.session_state.selected_model == "Hugging Face" else "secondary"):
            st.session_state.selected_model = "Hugging Face"
            st.rerun()

    # Ã–ne Ã§Ä±kan sohbet Ã¶rnekleri (sadece sohbet geÃ§miÅŸi boÅŸken gÃ¶ster)
    if not st.session_state.chat_history:
        show_featured_chats()

    # Sohbet geÃ§miÅŸini gÃ¶ster
    chat_container = st.container()
    with chat_container:
        st.markdown('<div class="chat-container">', unsafe_allow_html=True)
        for message in st.session_state.chat_history:
            if message["role"] == "user":
                st.markdown(
                    f'<div class="user-message">{message["content"]}</div>',
                    unsafe_allow_html=True
                )
            else:
                model_class = message.get("model", "gemini").lower()
                st.markdown(
                    f'<div class="bot-message {model_class}">{message["content"]}</div>',
                    unsafe_allow_html=True
                )
        st.markdown('</div>', unsafe_allow_html=True)

    # KullanÄ±cÄ± mesaj giriÅŸ alanÄ±
    with st.container():
        user_input = st.text_area(
            "Sorunuzu yazÄ±n:",
            height=120,
            key="user_input",
            value=st.session_state.get("user_input", ""),  # DeÄŸeri oturum durumundan al
            placeholder="SÃ¼rdÃ¼rÃ¼lebilir tekstil hakkÄ±nda sorunuzu buraya yazÄ±n...",
            label_visibility="collapsed"
        )

        # Butonlar iÃ§in yeni dÃ¼zen
        col1, col2 = st.columns([0.3, 0.7])

        with col1:
            if st.button("Temizle", type="secondary", use_container_width=True,
                         help="Sohbet geÃ§miÅŸini temizlemek iÃ§in tÄ±klayÄ±n",
                         on_click=clear_chat_history):
                pass

        with col2:
            submit_button = st.button("GÃ¶nder", type="primary", use_container_width=True)

    # Modelleri yÃ¼kle
    try:
        gemini_intent_model = load_gemini_model()
        hf_tokenizer, hf_model = load_hf_transformer_model()
    except Exception as e:
        st.error(f"Model yÃ¼klenirken hata oluÅŸtu: {str(e)}")
        return

    # Ã–ne Ã§Ä±kan sohbetten gÃ¶nderimi tetikle
    if st.session_state.trigger_submit:
        st.session_state.trigger_submit = False
        submit_button = True

    if (submit_button or st.session_state.trigger_submit) and user_input.strip():
        # KullanÄ±cÄ± mesajÄ±nÄ± geÃ§miÅŸe ekle
        st.session_state.chat_history.append({
            "role": "user",
            "content": user_input
        })

        with st.spinner("Cevap oluÅŸturuluyor..."):
            try:
                start_time = time.time()

                if st.session_state.selected_model == "Gemini":
                    # Niyet tahmini ve Gemini ile yanÄ±t oluÅŸtur
                    predicted_intent = gemini_intent_model.predict([user_input])[0]
                    prompt = build_prompt(predicted_intent, user_input)
                    response = generate_gemini_response(prompt)
                else:
                    # Niyet tahmini ve Hugging Face ile yanÄ±t oluÅŸtur
                    predicted_intent = hf_predict_intent(user_input, hf_tokenizer, hf_model)
                    prompt = build_prompt(predicted_intent, user_input)
                    response = generate_hf_response(prompt)

                logger.info(f"YanÄ±t oluÅŸturma sÃ¼resi: {time.time() - start_time:.2f}s")

            except Exception as e:
                logger.error(f"YanÄ±t oluÅŸturulurken hata: {str(e)}")
                response = "ÃœzgÃ¼nÃ¼m, bir hata oluÅŸtu. LÃ¼tfen daha sonra tekrar deneyin."

        # YanÄ±tÄ± geÃ§miÅŸe ekle
        st.session_state.chat_history.append({
            "role": "bot",
            "content": response,
            "model": "huggingface" if st.session_state.selected_model == "Hugging Face" else "gemini"
        })

        # SayfayÄ± yenile
        st.rerun()


if __name__ == "__main__":
    main()